{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c43e57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basis libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from PyPDF2 import PdfReader # Library to read PDFs\n",
    "from PyPDF2.errors import PdfReadError\n",
    "from IPython.display import display, Markdown\n",
    "import time\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Import Google libraries\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5957bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU google-generativeai python-dotenv pypdf2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8812e8",
   "metadata": {},
   "source": [
    "# Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a5b907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported setup_genai_client.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stephanie.creteur\\AppData\\Local\\miniconda3\\envs\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import setup function for Google GenAI client\n",
    "# This should be in a separate file named 'google_setup.py'\n",
    "try:\n",
    "    # Assumes revised Google_setup.py that returns model, generate_func, count_func\n",
    "    from google_setup import setup_genai_client\n",
    "    print(\"Successfully imported setup_genai_client.\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: Could not import setup_genai_client.\")\n",
    "    print(\"Make sure 'Google_setup.py' (revised version) is in the same directory.\")\n",
    "    # Define dummy functions if import fails\n",
    "    def setup_genai_client(model_name=\"dummy\"):\n",
    "        print(\"WARNING: Using dummy setup function. API calls and counts will not work.\")\n",
    "        class DummyModel:\n",
    "            def count_tokens(self, text): return len(text.split()) # Very rough approximation\n",
    "        def dummy_generate_text(prompt, config=None): return f\"Dummy response for prompt: {prompt[:50]}...\"\n",
    "        def dummy_count_tokens(text): return len(str(text).split()) # Rough approximation\n",
    "        return DummyModel(), dummy_generate_text, dummy_count_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model pricing (info)\n",
    "\"\"\"\n",
    "Model\tInput Price / 1M Tokens (USD)\tOutput Price / 1M Tokens (USD)\tEstimated Input Cost (USD) (301.5k tokens)\tEstimated Output Cost (USD) (3k tokens)\tTotal Estimated Cost (USD)\n",
    "Gemini 2.5 Pro Preview\t$1.25\t$10.00\t(0.3015 * 1.25) = $0.3769\t(0.003 * 10.00) = $0.0300\t~$0.4069\n",
    "Gemini 2.0 Flash\t$0.10\t$0.40\t(0.3015 * 0.10) = $0.0302\t(0.003 * 0.40) = $0.0012\t~$0.0314\n",
    "Gemini 2.0 Flash-Lite\t$0.075\t$0.30\t(0.3015 * 0.075) = $0.0226\t(0.003 * 0.30) = $0.0009\t~$0.0235\n",
    "Gemini 1.5 Flash\t$0.075\t$0.30\t(0.3015 * 0.075) = $0.0226\t(0.003 * 0.30) = $0.0009\t~$0.0235\n",
    "Gemini 1.5 Flash-8B\t$0.0375\t$0.15\t(0.3015 * 0.0375) = $0.0113\t(0.003 * 0.15) = $0.0005\t~$0.0118\n",
    "Gemini 1.5 Pro\t$1.25\t$5.00\t(0.3015 * 1.25) = $0.3769\t(0.003 * 5.00) = $0.0150\t~$0.3919\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12b35fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized model: gemini-2.0-flash\n",
      "Gemini client setup complete using model: gemini-2.0-flash\n",
      "\n",
      "Setup successful. Ready to process PDF.\n"
     ]
    }
   ],
   "source": [
    "# Define file path and model name\n",
    "# Ensure these are set correctly for your environment\n",
    "PDF_FILE_PATH = \"Articles/1-s2.0-S0959475223000166-main.pdf\" # <--- CONFIRM THIS PATH IS CORRECT\n",
    "MODEL_NAME = \"gemini-2.0-flash\" # Use a current valid model name (gemini-2.0-flash might not exist)\n",
    "\n",
    "# Initialize the Gemini text generation function\n",
    "try:\n",
    "    # setup_genai_client now returns only the function\n",
    "    generate_text = setup_genai_client(model_name=MODEL_NAME)\n",
    "    print(f\"Gemini client setup complete using model: {MODEL_NAME}\")\n",
    "    # Ensure generate_text is callable if needed for later checks\n",
    "    if not callable(generate_text):\n",
    "         print(\"Warning: setup_genai_client did not return a callable function.\")\n",
    "         generate_text = None # Set to None if setup technically succeeded but didn't return function\n",
    "\n",
    "except ValueError as e: # Catch API key error specifically if needed\n",
    "     print(f\"FATAL: Could not set up Gemini Client (check API KEY?). Error: {e}\")\n",
    "     generate_text = None # Ensure it's None if setup fails\n",
    "except Exception as e:\n",
    "    print(f\"FATAL: Could not set up Gemini Client. Exiting. Error: {e}\")\n",
    "    generate_text = None # Ensure it's None if setup fails\n",
    "\n",
    "# Check if setup succeeded before proceeding\n",
    "if generate_text is None:\n",
    "    print(\"\\n*** Setup failed. Cannot proceed with API calls. Please check errors above. ***\")\n",
    "else:\n",
    "    print(\"\\nSetup successful. Ready to process PDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b092f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to read PDF files\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from all pages of a PDF file using PyPDF2.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The full path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: The concatenated text extracted from all pages,\n",
    "             or an empty string if the file cannot be read or no text is found.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the pdf_path does not exist.\n",
    "        PdfReadError: If PyPDF2 encounters issues reading the PDF structure.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"Error: PDF file not found at {pdf_path}\")\n",
    "\n",
    "    print(f\"Reading PDF: {os.path.basename(pdf_path)}...\")\n",
    "    text = \"\"\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        num_pages = len(reader.pages)\n",
    "        print(f\"Found {num_pages} pages.\")\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            try:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:  # Add text only if extraction was successful\n",
    "                    text += page_text + \"\\n\\n\"  # Add page separator\n",
    "                # else:\n",
    "                    # Optional: Log pages with no text\n",
    "                    # print(f\"  Note: No text extracted from page {i+1}.\")\n",
    "            except Exception as page_error:\n",
    "                # Log errors extracting text from specific pages but continue\n",
    "                print(f\"Warning: Could not extract text from page {i+1}. Error: {page_error}\")\n",
    "        print(f\"Finished text extraction attempt.\")\n",
    "        return text\n",
    "    except PdfReadError as e:\n",
    "        # Specific error for PDF reading issues (corruption, encryption etc.)\n",
    "        print(f\"Error reading PDF structure (maybe corrupted, encrypted, or non-standard): {e}\")\n",
    "        raise  # Re-raise this error as it likely prevents further processing\n",
    "    except Exception as e:\n",
    "        # Catch other potential errors during PdfReader initialization etc.\n",
    "        print(f\"An unexpected error occurred during PDF reading initialization: {e}\")\n",
    "        raise # Re-raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df07c80c",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERARCHING_PROMPT = \"\"\"You are an academic data extractor assistant. Your task is to extract specific information from the provided text of an academic article based on the user's prompt.\n",
    "Rules:\n",
    "1. Respond **only** with the extracted information requested by the prompt. Do **not** include any introductory phrases, explanations, or conversational text like 'Here is the title:', 'The authors are:', 'Based on the text:', 'The answer is:', etc.\n",
    "2. Use **British English** spelling throughout your response (e.g., 'analyse', 'centre', 'behaviour').\n",
    "3. Specifically use the word '**competences**' instead of 'competencies' whenever the concept arises.\n",
    "4. Provide plain text answers. Do not use markdown formatting like bolding or bullet points unless the extracted text itself contains them.\"\"\"\n",
    "\n",
    "prompts = {\n",
    "    \"Title\": \"Directly state the exact title of the study from the provided text.\",\n",
    "    #\"Author\": \"List the full names of the authors for this study from the provided text, separated by commas or as listed.\",\n",
    "    \"Abstract\": \"Provide the complete abstract of the study from the provided text.\",\n",
    "    \"Journal\": \"Directly state the name of the journal, working paper series, or other publication source mentioned in the text.\",\n",
    "    #\"Country\": \"List the specific EU country or countries (excluding EFTA members Iceland, Liechtenstein, Norway, Switzerland) where the study was conducted, as mentioned in the text. If multiple, separate by commas. If none mentioned or only EFTA countries, state 'None EU specified'.\",\n",
    "    #\"Year\": \"Directly state the year of publication extracted from the text.\",\n",
    "    #\"Educational Level\": \"Directly state the most specific educational level(s) targeted or studied (e.g., ECEC/Preschool, Primary, Secondary, Tertiary/Higher Education).\",\n",
    "    \"Method\": \"\"\"Identify the study's core methodology based on whether it uses a counterfactual design aiming to estimate a causal effect.\n",
    "- If the text describes random assignment of participants to treatment and control groups, classify as 'Randomised experiment (RCT)'.\n",
    "- If the text describes a non-random method designed to estimate a causal effect by creating a comparison group (look for terms like Difference-in-Differences, Regression Discontinuity, Instrumental Variables, Propensity Score Matching, Interrupted Time Series, matching, comparison group without randomisation), classify as 'Quasi-experimental'. If a specific method like 'Propensity Score Matching' is mentioned, state 'Quasi-experimental (Propensity Score Matching)'. If the type is unclear but a non-random comparison is used, state 'Quasi-experimental (Other QE)'.\n",
    "- If the study is primarily descriptive, correlational, theoretical, qualitative without a focus on estimating causal effects via comparison groups, or a review/meta-analysis not focused on counterfactual estimation, classify as 'Not a counterfactual study'.\n",
    "Provide only the final classification category name.\"\"\",\n",
    "    #\"Policy area\": \"List the main policy area(s) addressed (e.g., competences and skills, private education, career guidance, disadvantaged students, migrant students, institutional aspects, education drop-out/completion/participation, digital tools, teaching profession). Separate multiple areas with commas.\",\n",
    "    \"Specific type of educational intervention or policy evaluated in the study\": \"Directly describe the specific educational intervention, program, policy, or phenomenon evaluated or analysed in the study.\",\n",
    "    \"Core findings\": \"Summarise the main conclusions and core findings reported in the text. Include key results regarding effects, comparisons, and positive/negative/null findings. Present as a single block of text.\",\n",
    "    \"Target population\": \"Directly describe the specific group(s) or entities the study focused on, including key characteristics mentioned (age, role, location, etc.).\",\n",
    "    \"Outcome domain\": \"Identify the broad category or domain of the primary outcome(s) measured in the study (e.g., academic achievement, interaction quality, enrollment, student retention). Provide only the domain name(s).\", # Removed the confusing examples from the prompt itself\n",
    "    \"Effect Summary\": \"Provide a concise summary integrating the direction (Positive, Negative, Mixed, None), magnitude (effect size, % change, score difference), and statistical significance (p-value, CI) of the main effect(s). Present as a single block of text.\",\n",
    "    \"Implementation duration\": \"Directly describe the duration of the intervention or observation period mentioned in the text.\",\n",
    "    \"Sample size (description)\": \"Provide a brief description of the sample size, including the units counted (e.g., teachers, pupils, schools).\",\n",
    "    \"Sample size (raw number)\": \"Directly state the primary raw number representing the total sample size for the main analysis.\",\n",
    "    \"Publication Reference\": \"Extract the publication reference details (Journal/Source, volume, issue, pages) as available in the text.\",\n",
    "    \"Study limitation\": \"List the methodological limitations or constraints acknowledged by the authors or evident in the text. Separate distinct limitations. Focus on validity/generalisability aspects, not null findings.\",\n",
    "    \"Tagging system\": \"List any keywords, tags, or subject classifications provided in the text, separated by commas.\"\n",
    "    # \"Weblink\": \"Extract any DOI or URL weblink provided in the text.\" \n",
    "}\n",
    "\n",
    "#prompts = {\"Title\": \"Just write test\", \"Year\": \"The year should be 2023\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86676526",
   "metadata": {},
   "source": [
    "# Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "605c9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract text from a PDF file\n",
    "def process_single_pdf(pdf_path, prompts_dict, generate_text_func, system_prompt=\"\"):\n",
    "    \"\"\"\n",
    "    Reads a PDF, applies multiple prompts using the Gemini API via generate_text_func,\n",
    "    prepending a system prompt to each call, and returns a dictionary of extracted data.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The full path to the PDF file.\n",
    "        prompts_dict (dict): A dictionary where keys are field names and values\n",
    "                             are the corresponding specific task prompts.\n",
    "        generate_text_func (function): The function that calls the Gemini API.\n",
    "        system_prompt (str, optional): General instructions for the model\n",
    "                                       to prepend to each specific prompt. Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted data for each field,\n",
    "              or None if the PDF cannot be read. Keys match the prompts_dict keys.\n",
    "              Values can include error messages if API calls fail for specific fields.\n",
    "    \"\"\"\n",
    "    # --- Basic Checks ---\n",
    "    if not callable(generate_text_func):\n",
    "        print(\"Error: Invalid generate_text_func provided to process_single_pdf.\")\n",
    "        return None\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"Error: PDF file not found at {pdf_path}\")\n",
    "        return {\"filename\": os.path.basename(pdf_path), \"status\": \"Error - File not found\"}\n",
    "\n",
    "    # --- Step 1: Extract text from PDF ---\n",
    "    pdf_filename = os.path.basename(pdf_path)\n",
    "    print(f\"\\n--- Reading PDF: {pdf_filename} ---\")\n",
    "    try:\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        if not pdf_text:\n",
    "            print(f\"Warning: No text extracted from '{pdf_filename}'. Cannot process.\")\n",
    "            return {\"filename\": pdf_filename, \"status\": \"Error - No text extracted\"}\n",
    "        print(f\"Successfully extracted text from {pdf_filename}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF '{pdf_filename}': {e}\")\n",
    "        return {\"filename\": pdf_filename, \"status\": f\"Error - PDF Read Failed: {e}\"}\n",
    "\n",
    "    # --- Step 2: Process Prompts using Gemini ---\n",
    "    extracted_data = {\"filename\": pdf_filename}\n",
    "    num_prompts = len(prompts_dict)\n",
    "    print(f\"--- Starting API calls for {pdf_filename} ({num_prompts} fields) ---\")\n",
    "\n",
    "    for i, (field, specific_prompt) in enumerate(prompts_dict.items()):\n",
    "        print(f\"  Processing field {i+1}/{num_prompts}: {field}...\")\n",
    "\n",
    "        # *** MODIFICATION: Construct the full prompt including the system prompt ***\n",
    "        full_prompt = f\"{system_prompt}\\n\\nTASK:\\n{specific_prompt}\\n\\nDOCUMENT TEXT:\\n---\\n{pdf_text}\\n---\"\n",
    "\n",
    "        # Call the API using the provided function\n",
    "        try:\n",
    "            response_text = generate_text_func(prompt=full_prompt)\n",
    "            response_text = response_text.strip()\n",
    "            # Basic cleanup for potential markdown code blocks\n",
    "            if response_text.startswith(\"```\"):\n",
    "                 lines = response_text.split('\\n')\n",
    "                 if len(lines) > 1 and lines[-1] == \"```\": # Check if it has start/end ```\n",
    "                     # Try to extract text between ```, removing potential language identifier\n",
    "                     response_text = \"\\n\".join(lines[1:-1]).strip()\n",
    "                 elif len(lines) > 0: # If only start ```, remove it and potential lang identifier\n",
    "                      response_text = response_text.lstrip('`').strip()\n",
    "                      # Find first newline if present after initial ```\n",
    "                      first_newline = response_text.find('\\n')\n",
    "                      if first_newline != -1:\n",
    "                          response_text = response_text[first_newline:].strip()\n",
    "\n",
    "\n",
    "            extracted_data[field] = response_text\n",
    "            print(f\"    Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR calling Gemini API for field '{field}': {e}\")\n",
    "            extracted_data[field] = f\"API Error: {e}\"\n",
    "\n",
    "        # Optional: time.sleep(1)\n",
    "\n",
    "    print(f\"--- Finished processing prompts for {pdf_filename} ---\")\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0d191c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured destination folder exists: 'Articles_done/'\n",
      "Found 1 PDF files to process.\n",
      "\n",
      "--- Reading PDF: 1-s2.0-S0959475223000166-main.pdf ---\n",
      "Reading PDF: 1-s2.0-S0959475223000166-main.pdf...\n",
      "Found 13 pages.\n",
      "Finished text extraction attempt.\n",
      "Successfully extracted text from 1-s2.0-S0959475223000166-main.pdf.\n",
      "--- Starting API calls for 1-s2.0-S0959475223000166-main.pdf (2 fields) ---\n",
      "  Processing field 1/2: Title...\n",
      "    Success.\n",
      "  Processing field 2/2: Year...\n",
      "    Success.\n",
      "--- Finished processing prompts for 1-s2.0-S0959475223000166-main.pdf ---\n",
      "  Successfully processed data for '1-s2.0-S0959475223000166-main.pdf'. Attempting to rename and move...\n",
      "    Moving 'Articles/1-s2.0-S0959475223000166-main.pdf' to 'Articles_done/2023 - test.pdf'\n",
      "    Successfully moved and renamed '1-s2.0-S0959475223000166-main.pdf'.\n",
      "\n",
      "Converting extracted data to DataFrame...\n",
      "\n",
      "Saving extracted data to Excel file: 'Extracted_Article_Data.xlsx'...\n",
      "Successfully saved results to c:\\Users\\stephanie.creteur\\Coding\\ENESET database extractor\\Extracted_Article_Data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "PDF_FOLDER_PATH = \"Articles/\"\n",
    "DESTINATION_FOLDER_PATH = \"Articles_done/\"\n",
    "OUTPUT_EXCEL_FILENAME = \"Extracted_Article_Data.xlsx\"\n",
    "\n",
    "# --- Main Batch Processing Logic ---\n",
    "\n",
    "if 'generate_text' not in locals() or not callable(generate_text):\n",
    "    print(\"\\nERROR: 'generate_text' function is not defined or setup failed.\")\n",
    "    print(\"Please run the Gemini client setup cell successfully first.\")\n",
    "else:\n",
    "    if not os.path.isdir(PDF_FOLDER_PATH):\n",
    "        print(f\"Error: Source PDF folder not found at '{PDF_FOLDER_PATH}'\")\n",
    "    else:\n",
    "        # --- Create Destination Folder ---\n",
    "        try:\n",
    "            os.makedirs(DESTINATION_FOLDER_PATH, exist_ok=True)\n",
    "            print(f\"Ensured destination folder exists: '{DESTINATION_FOLDER_PATH}'\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating destination folder '{DESTINATION_FOLDER_PATH}': {e}\")\n",
    "            # Optionally exit if destination can't be created\n",
    "            # exit()\n",
    "\n",
    "        # Discover PDF files\n",
    "        pdf_files = [f for f in os.listdir(PDF_FOLDER_PATH) if f.lower().endswith('.pdf') and os.path.isfile(os.path.join(PDF_FOLDER_PATH, f))]\n",
    "        pdf_files.sort()\n",
    "\n",
    "        if not pdf_files:\n",
    "            print(f\"No PDF files found in folder: '{PDF_FOLDER_PATH}'\")\n",
    "        else:\n",
    "            print(f\"Found {len(pdf_files)} PDF files to process.\")\n",
    "\n",
    "            all_results = [] # To store extracted data for Excel\n",
    "\n",
    "            # Loop through each PDF file\n",
    "            for pdf_filename in pdf_files:\n",
    "                source_pdf_path = os.path.join(PDF_FOLDER_PATH, pdf_filename)\n",
    "\n",
    "                # Process the single PDF using the existing function\n",
    "                extracted_data = process_single_pdf(\n",
    "                    pdf_path=source_pdf_path,\n",
    "                    prompts_dict=prompts,\n",
    "                    generate_text_func=generate_text,\n",
    "                    system_prompt=OVERARCHING_PROMPT\n",
    "                )\n",
    "\n",
    "                # Add the result (even if it's an error dictionary) for Excel export\n",
    "                if extracted_data:\n",
    "                    # Always add filename from the source, not the potentially failing extracted data\n",
    "                    extracted_data['original_filename'] = pdf_filename\n",
    "                    all_results.append(extracted_data)\n",
    "\n",
    "                    # --- Rename and Move Logic (Only if processing was successful) ---\n",
    "                    if not isinstance(extracted_data, dict) or not extracted_data.get(\"status\", \"\").startswith(\"Error\"):\n",
    "                        print(f\"  Successfully processed data for '{pdf_filename}'. Attempting to rename and move...\")\n",
    "                        try:\n",
    "                            # Extract Year\n",
    "                            year_text = extracted_data.get(\"Year\", \"\")\n",
    "                            year_match = re.search(r'\\b(19|20)\\d{2}\\b', str(year_text)) # Convert to str just in case\n",
    "                            parsed_year = year_match.group(0) if year_match else \"UnknownYear\"\n",
    "\n",
    "                            # Extract and Sanitize Title\n",
    "                            title_text = extracted_data.get(\"Title\", \"\")\n",
    "                            sanitized_title = sanitize_filename(title_text) if title_text else \"UnknownTitle\"\n",
    "\n",
    "                            # Handle cases where title might still be empty after sanitizing\n",
    "                            if not sanitized_title:\n",
    "                                sanitized_title = \"UnknownTitle\"\n",
    "\n",
    "                            # Construct new filename\n",
    "                            new_pdf_name = f\"{parsed_year} - {sanitized_title}.pdf\"\n",
    "                            destination_pdf_path = os.path.join(DESTINATION_FOLDER_PATH, new_pdf_name)\n",
    "\n",
    "                            # --- Move and Rename ---\n",
    "                            print(f\"    Moving '{source_pdf_path}' to '{destination_pdf_path}'\")\n",
    "                            shutil.move(source_pdf_path, destination_pdf_path)\n",
    "                            print(f\"    Successfully moved and renamed '{pdf_filename}'.\")\n",
    "\n",
    "                        except KeyError as e:\n",
    "                            print(f\"    Warning: Could not find key '{e}' in extracted data for '{pdf_filename}'. Cannot rename/move.\")\n",
    "                        except OSError as e:\n",
    "                            print(f\"    Error moving/renaming file '{pdf_filename}': {e}. Check permissions or if file is open.\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"    An unexpected error occurred during renaming/moving of '{pdf_filename}': {e}\")\n",
    "                    else:\n",
    "                        # Processing failed, don't move the file\n",
    "                        print(f\"  Processing failed for '{pdf_filename}'. File will not be renamed or moved.\")\n",
    "                        # Log the error status if available\n",
    "                        if isinstance(extracted_data, dict):\n",
    "                             print(f\"  Reason: {extracted_data.get('status', 'Unknown processing error')}\")\n",
    "\n",
    "                else:\n",
    "                     print(f\"  Processing returned no result for '{pdf_filename}'. File will not be moved.\")\n",
    "\n",
    "\n",
    "            # --- Post-Processing: Save aggregated data to Excel ---\n",
    "            if not all_results:\n",
    "                print(\"\\nNo results were generated to save.\")\n",
    "            else:\n",
    "                print(\"\\nConverting extracted data to DataFrame...\")\n",
    "                df = pd.DataFrame(all_results)\n",
    "\n",
    "                # Define desired column order (match keys in prompts + original_filename + status)\n",
    "                desired_columns = ['original_filename'] + list(prompts.keys()) + ['status']\n",
    "                actual_columns = [col for col in desired_columns if col in df.columns]\n",
    "                df = df[actual_columns] # Reorder/filter columns\n",
    "\n",
    "                # Construct static output filepath\n",
    "                output_filepath = os.path.join(os.getcwd(), OUTPUT_EXCEL_FILENAME) # Save in current dir\n",
    "\n",
    "                # Save DataFrame to Excel\n",
    "                try:\n",
    "                    print(f\"\\nSaving extracted data to Excel file: '{OUTPUT_EXCEL_FILENAME}'...\")\n",
    "                    df.to_excel(output_filepath, index=False, engine='openpyxl')\n",
    "                    print(f\"Successfully saved results to {output_filepath}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError saving results to Excel: {e}\")\n",
    "                    # Add CSV fallback if needed\n",
    "                    # output_csv_filepath = os.path.join(os.getcwd(), OUTPUT_EXCEL_FILENAME.replace('.xlsx', '.csv'))\n",
    "                    # try:\n",
    "                    #    df.to_csv(output_csv_filepath, index=False)\n",
    "                    #    print(f\"Successfully saved results as CSV to {output_csv_filepath}\")\n",
    "                    # except Exception as csv_e:\n",
    "                    #    print(f\"Error saving as CSV: {csv_e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
